{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62951996",
   "metadata": {},
   "source": [
    "# Code For The Entire Procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87085c33",
   "metadata": {},
   "source": [
    "### Import all libraries nessecary. Librosa is the library that executes algorithms to extract feature from .wav sample audio files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64bdd7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import math\n",
    "import json\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0fe047",
   "metadata": {},
   "source": [
    "### Each audio track is 30 seconds long. Define that the sampling rate is 1 second per sample.  At each second, the Band Energy Ratio (BER), Mel-Frequency Cspstral Coefficients (MFCCs), their derivatives, spectral centriods (SC), and zero-crossing (ZCF) rates are taken."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187ec4a8",
   "metadata": {},
   "source": [
    "### Each track will have 30 sample extractions (and so each track maps to the 30 of them), where each sample contains multiple features. The feature dimensions for each audio track after feature generation is 30-by-the-count-of-all-features-per-sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8370f6",
   "metadata": {},
   "source": [
    "### There are 1000 tracks and 10 genres in total, where each 100 tracks are labeled to one genre. Each track is 30 seconds long, and each track will be sampled 30 times, 1 time per second."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18e1d63",
   "metadata": {},
   "source": [
    "### The 1000 tracks with all their sampled features is stored in \"data.json\" file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eff15fe2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = \"genres\"\n",
    "JSON_PATH = \"data.json\"\n",
    "\n",
    "SAMPLE_RATE = 22050\n",
    "DURATION = 30\n",
    "SAMPLES_PER_TRACK = SAMPLE_RATE * DURATION\n",
    "SEGMENTS_PER_TRACK = 30\n",
    "\n",
    "FRAME_SIZE = 2048\n",
    "HOP_SIZE = 512\n",
    "\n",
    "num_samples_per_segment = int(SAMPLES_PER_TRACK / SEGMENTS_PER_TRACK)\n",
    "expected_num_mfcc_vectors_per_segment = math.ceil(num_samples_per_segment / HOP_SIZE)\n",
    "\n",
    "\n",
    "def calculate_split_frequency_bin(spectrogram, split_frequency, sample_rate):\n",
    "    \n",
    "    frequency_range = sample_rate/2\n",
    "    frequency_delta_per_bin = frequency_range / spectrogram.shape[0]\n",
    "    split_frequency_bin = np.floor(split_frequency / frequency_delta_per_bin)\n",
    "    return int(split_frequency_bin)\n",
    "\n",
    "def calculate_band_energy_ratio(spectrogram, split_frequency, sample_rate):\n",
    "    \n",
    "    split_frequency_bin = calculate_split_frequency_bin(spectrogram, split_frequency, sample_rate)\n",
    "    \n",
    "    power_spec = np.abs(spectrogram)**2\n",
    "    power_spec = power_spec.T\n",
    "    \n",
    "    band_energy_ratio = []\n",
    "    \n",
    "    for frequency_in_frame in power_spec:\n",
    "        sum_power_low_frequencies = np.sum(frequency_in_frame[:split_frequency_bin])\n",
    "        sum_power_high_frequencies = np.sum(frequency_in_frame[split_frequency_bin:])\n",
    "        ber_current_frame = sum_power_high_frequencies / sum_power_low_frequencies\n",
    "        if math.isnan(ber_current_frame):\n",
    "            band_energy_ratio.append(100)\n",
    "        else:\n",
    "            band_energy_ratio.append(ber_current_frame)\n",
    "        \n",
    "    return np.array(band_energy_ratio)\n",
    "\n",
    "def process_audio_data(dataset_path=DATASET_PATH,\n",
    "                       json_path=JSON_PATH,\n",
    "                       n_mfcc=13,\n",
    "                       n_fft=FRAME_SIZE,\n",
    "                       hop_length=HOP_SIZE,\n",
    "                       num_segments=SEGMENTS_PER_TRACK):\n",
    "    \n",
    "    data = {\n",
    "        \"mapping\": [],\n",
    "        \"tracks\": [],\n",
    "        \"labels\": []\n",
    "    }\n",
    "    \n",
    "    for i, (dirpath, dirnames, filenames) in enumerate(os.walk(dataset_path)):\n",
    "        \n",
    "        if dirpath is not dataset_path:\n",
    "            dirpath_components = dirpath.split(\"/\")\n",
    "            semantic_label = dirpath_components[-1]\n",
    "            \n",
    "            data[\"mapping\"].append(semantic_label)\n",
    "            print(\"\\nProcessing {}\".format(semantic_label))\n",
    "            \n",
    "            for f in filenames:\n",
    "                \n",
    "                file_path = os.path.join(dirpath, f)\n",
    "                signal, sr = librosa.load(file_path, sr=SAMPLE_RATE)\n",
    "                \n",
    "                track = {\n",
    "                    \"mfcc_m\": [],\n",
    "                    \"mfcc_s\": [],\n",
    "                    \"mfcc1_m\": [],\n",
    "                    \"mfcc1_s\": [],\n",
    "                    \"mfcc2_m\": [],\n",
    "                    \"mfcc2_s\": [],\n",
    "                    \"ber1000_m\": [],\n",
    "                    \"ber1000_s\": [],\n",
    "                    \"ber2000_m\": [],\n",
    "                    \"ber2000_s\": [],\n",
    "                    \"ber3000_m\": [],\n",
    "                    \"ber3000_s\": [],\n",
    "                    \"centroid_m\": [],\n",
    "                    \"centroid_s\": [],\n",
    "                    \"bandwidth_m\": [],\n",
    "                    \"bandwidth_s\": [],\n",
    "                    \"zcr_m\": [],\n",
    "                    \"zcr_s\": [],\n",
    "                    \"labels\": []\n",
    "                }\n",
    "                \n",
    "                for s in range(num_segments):\n",
    "                    \n",
    "                    start_sample = num_samples_per_segment * s\n",
    "                    finish_sample = start_sample + num_samples_per_segment\n",
    "                    \n",
    "                    mfcc = librosa.feature.mfcc(signal[start_sample:finish_sample], \n",
    "                                                sr=sr,\n",
    "                                                n_fft=n_fft,\n",
    "                                                n_mfcc=n_mfcc,\n",
    "                                                hop_length=hop_length)\n",
    "                    mfccs = mfcc.T\n",
    "                    \n",
    "                    if len(mfccs)==expected_num_mfcc_vectors_per_segment:\n",
    "                        \n",
    "                        track[\"mfcc_m\"].append(np.mean(mfccs, 0).tolist())\n",
    "                        track[\"mfcc_s\"].append(np.std(mfccs, 0).tolist())\n",
    "                        \n",
    "                        delta_mfccs = librosa.feature.delta(mfcc).T\n",
    "                        delta2_mfccs = librosa.feature.delta(mfcc, order=2).T\n",
    "                        \n",
    "                        track[\"mfcc1_m\"].append(np.mean(delta_mfccs, 0).tolist())\n",
    "                        track[\"mfcc1_s\"].append(np.std(delta_mfccs, 0).tolist())\n",
    "                        track[\"mfcc2_m\"].append(np.mean(delta2_mfccs, 0).tolist())\n",
    "                        track[\"mfcc2_s\"].append(np.std(delta2_mfccs, 0).tolist())\n",
    "                        \n",
    "                        s_music = librosa.stft(signal[start_sample:finish_sample], n_fft=n_fft, hop_length=hop_length)\n",
    "                    \n",
    "                        ber_music1000 = calculate_band_energy_ratio(s_music, 1000, sr) \n",
    "                        track[\"ber1000_m\"].append(np.mean(ber_music1000).tolist())\n",
    "                        track[\"ber1000_s\"].append(np.std(ber_music1000).tolist())\n",
    "                        \n",
    "                        ber_music2000 = calculate_band_energy_ratio(s_music, 2000, sr) \n",
    "                        track[\"ber2000_m\"].append(np.mean(ber_music2000).tolist())\n",
    "                        track[\"ber2000_s\"].append(np.std(ber_music2000).tolist())\n",
    "                        \n",
    "                        ber_music3000 = calculate_band_energy_ratio(s_music, 3000, sr) \n",
    "                        track[\"ber3000_m\"].append(np.mean(ber_music3000).tolist())\n",
    "                        track[\"ber3000_s\"].append(np.std(ber_music3000).tolist())\n",
    "\n",
    "                        sc_music = librosa.feature.spectral_centroid(y=signal[start_sample:finish_sample], sr=sr, n_fft=n_fft, hop_length=hop_length)[0]\n",
    "                        track[\"centroid_m\"].append(np.mean(sc_music).tolist())\n",
    "                        track[\"centroid_s\"].append(np.std(sc_music).tolist())\n",
    "\n",
    "                        bdwh_music = librosa.feature.spectral_bandwidth(y=signal[start_sample:finish_sample], sr=sr, n_fft=n_fft, hop_length=hop_length)[0]\n",
    "                        track[\"bandwidth_m\"].append(np.mean(bdwh_music).tolist())\n",
    "                        track[\"bandwidth_s\"].append(np.std(bdwh_music).tolist())\n",
    "                        \n",
    "                        zcr_music = librosa.feature.zero_crossing_rate(y=signal[start_sample:finish_sample], frame_length=n_fft, hop_length=hop_length)[0]\n",
    "                        track[\"zcr_m\"].append(np.mean(zcr_music).tolist())\n",
    "                        track[\"zcr_s\"].append(np.std(zcr_music).tolist())\n",
    "                        \n",
    "                        track[\"labels\"].append(i-1)\n",
    "                \n",
    "                data[\"tracks\"].append(track)\n",
    "                data[\"labels\"].append(i-1)\n",
    "                \n",
    "    with open(json_path, \"w\") as fp:\n",
    "        json.dump(data, fp, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a61bc078",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing pop\n",
      "\n",
      "Processing metal\n",
      "\n",
      "Processing disco\n",
      "\n",
      "Processing blues\n",
      "\n",
      "Processing reggae\n",
      "\n",
      "Processing classical\n",
      "\n",
      "Processing rock\n",
      "\n",
      "Processing hiphop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-bbf2546ce20c>:35: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  ber_current_frame = sum_power_high_frequencies / sum_power_low_frequencies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing country\n",
      "\n",
      "Processing jazz\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    process_audio_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93aae054",
   "metadata": {},
   "source": [
    "## Perform K-means clustering algorithm based on each 1-second sample, asserting that each 1-second sample (of all 1000 tracks, 30 samples per track, 30000 total) has enough information that each sample can be disdinguished and classified among the other 1-second samples. If this assertion is true, then the clustering results from the K-means algorithm may show noticeable patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d48cd452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29991, 91)\n"
     ]
    }
   ],
   "source": [
    "data = json.load(open(\"data.json\"))\n",
    "\n",
    "data_features_by_segments = [];\n",
    "count = 0;\n",
    "\n",
    "for j in range(len(data[\"tracks\"])):\n",
    "\n",
    "    samples = np.array([data[\"tracks\"][j][i] for i in data[\"tracks\"][j]], dtype=object)\n",
    "    new_new_samples = np.asarray([samples[i] for i in range(len(samples))], dtype=object)\n",
    "    first_row = np.asarray([new_new_samples[0][i] for i in range(len(new_new_samples[0]))], dtype=object)\n",
    "    second_row = np.asarray([new_new_samples[1][i] for i in range(len(new_new_samples[1]))], dtype=object)\n",
    "    third_row = np.asarray([new_new_samples[2][i] for i in range(len(new_new_samples[2]))], dtype=object)\n",
    "    fourth_row = np.asarray([new_new_samples[3][i] for i in range(len(new_new_samples[3]))], dtype=object)\n",
    "    fifth_row = np.asarray([new_new_samples[4][i] for i in range(len(new_new_samples[4]))], dtype=object)\n",
    "    sixth_row = np.asarray([new_new_samples[5][i] for i in range(len(new_new_samples[5]))], dtype=object)\n",
    "    rest = new_new_samples[6:].T\n",
    "\n",
    "    dataset = np.concatenate((first_row, second_row, third_row, fourth_row, fifth_row, sixth_row, rest), 1)\n",
    "    \n",
    "    if count==0:\n",
    "        data_features_by_segments = dataset\n",
    "        count-=1\n",
    "    else:\n",
    "        data_features_by_segments = np.concatenate((data_features_by_segments, dataset), 0)\n",
    "\n",
    "print(data_features_by_segments.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8434a624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    return (x-np.mean(x))/np.std(x)\n",
    "\n",
    "def K_Means(X, K, error_threshold):\n",
    "    \n",
    "    m = np.zeros((K, X.shape[1]))\n",
    "    sample_window_size = int(X.shape[0]/K)\n",
    "    \n",
    "    for i in range(0, K):\n",
    "        m[i] = X[np.random.choice(sample_window_size, 1, replace=False) + i*sample_window_size]\n",
    "    \n",
    "    D = 1000000\n",
    "    difference = 10.0\n",
    "    \n",
    "    while difference > error_threshold:\n",
    "    \n",
    "        current_distortion = 0\n",
    "        C = {n: [] for n in range(K)}\n",
    "        \n",
    "        for row in X:\n",
    "            error = np.sum((row[:-1]-m[:,:-1])**2, axis=1)**0.5\n",
    "            min_index = np.argmin(error)\n",
    "            current_distortion += error[min_index]\n",
    "            C[min_index].append(row) \n",
    "            \n",
    "        for samples_by_cluster in C:\n",
    "            temp = np.asarray(C[samples_by_cluster])\n",
    "            m[samples_by_cluster,:-1] = np.mean(temp[:,:-1],0)\n",
    "        \n",
    "        difference = abs(current_distortion-D)\n",
    "        D = current_distortion\n",
    "\n",
    "    return(m, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28898bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_dataset_by_segments = data_features_by_segments\n",
    "normalized_dataset_by_segments[:,:-1] = normalize(normalized_dataset_by_segments[:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bae7f5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_means_and_display_by_number_of_cluster_centers(centroids, normalized_dataset, error_threshold):\n",
    "\n",
    "    m, D = K_Means(normalized_dataset, centroids, error_threshold)\n",
    "\n",
    "    genre_count = np.zeros((centroids, len(data[\"mapping\"])))\n",
    "    genres = np.asarray(data[\"mapping\"])\n",
    "\n",
    "    for idx in range(normalized_dataset.shape[0]):\n",
    "        distance = np.sum((normalized_dataset[idx,:-1]-m[:,:-1])**2, axis=1)\n",
    "        centroid = np.argmin(distance)\n",
    "        genre = normalized_dataset[idx][-1]\n",
    "        genre_count[centroid][int(genre)] += 1\n",
    "\n",
    "    print('\\t',end=\"\")\n",
    "\n",
    "    genres[5] = \"classic\"\n",
    "\n",
    "    for genre in genres:\n",
    "        print(genre+'\\t',end=\"\")\n",
    "    print('\\n')\n",
    "\n",
    "    for i in range(genre_count.shape[0]):\n",
    "        print('K = %d \\t'%i,end=\"\")\n",
    "        for j in range(genre_count.shape[1]):\n",
    "            print(str(int(genre_count[i,j]))+'\\t',end=\"\")\n",
    "        print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd81b2f5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trying with 2 centroids:\n",
      "\n",
      "\tpop\tmetal\tdisco\tblues\treggae\tclassic\trock\thiphop\tcountry\tjazz\t\n",
      "\n",
      "K = 0 \t252\t710\t638\t2284\t1545\t2909\t1415\t694\t2045\t2205\t\n",
      "\n",
      "K = 1 \t2748\t2290\t2361\t716\t1455\t89\t1584\t2304\t952\t795\t\n",
      "\n",
      "Try Complete.\n",
      "\n",
      "\n",
      "Trying with 3 centroids:\n",
      "\n",
      "\tpop\tmetal\tdisco\tblues\treggae\tclassic\trock\thiphop\tcountry\tjazz\t\n",
      "\n",
      "K = 0 \t2216\t485\t1011\t43\t564\t14\t483\t976\t368\t361\t\n",
      "\n",
      "K = 1 \t711\t2364\t1863\t1428\t1652\t300\t1881\t1797\t1241\t934\t\n",
      "\n",
      "K = 2 \t73\t151\t125\t1529\t784\t2684\t635\t225\t1388\t1705\t\n",
      "\n",
      "Try Complete.\n",
      "\n",
      "\n",
      "Trying with 4 centroids:\n",
      "\n",
      "\tpop\tmetal\tdisco\tblues\treggae\tclassic\trock\thiphop\tcountry\tjazz\t\n",
      "\n",
      "K = 0 \t808\t2040\t1587\t592\t909\t71\t1177\t1525\t685\t519\t\n",
      "\n",
      "K = 1 \t283\t764\t742\t1306\t1427\t581\t1252\t774\t1289\t1037\t\n",
      "\n",
      "K = 2 \t26\t46\t24\t1092\t287\t2337\t306\t64\t849\t1226\t\n",
      "\n",
      "K = 3 \t1883\t150\t646\t10\t377\t9\t264\t635\t174\t218\t\n",
      "\n",
      "Try Complete.\n",
      "\n",
      "\n",
      "Trying with 5 centroids:\n",
      "\n",
      "\tpop\tmetal\tdisco\tblues\treggae\tclassic\trock\thiphop\tcountry\tjazz\t\n",
      "\n",
      "K = 0 \t1554\t73\t461\t5\t278\t3\t160\t452\t93\t139\t\n",
      "\n",
      "K = 1 \t954\t1230\t1096\t174\t579\t23\t670\t1078\t475\t421\t\n",
      "\n",
      "K = 2 \t125\t216\t252\t1014\t1008\t902\t730\t356\t1151\t1071\t\n",
      "\n",
      "K = 3 \t352\t1467\t1184\t1013\t1028\t189\t1309\t1086\t762\t468\t\n",
      "\n",
      "K = 4 \t15\t14\t6\t794\t107\t1881\t130\t26\t516\t901\t\n",
      "\n",
      "Try Complete.\n",
      "\n",
      "\n",
      "Trying with 6 centroids:\n",
      "\n",
      "\tpop\tmetal\tdisco\tblues\treggae\tclassic\trock\thiphop\tcountry\tjazz\t\n",
      "\n",
      "K = 0 \t1313\t48\t348\t3\t221\t2\t107\t329\t62\t104\t\n",
      "\n",
      "K = 1 \t1087\t615\t932\t78\t476\t17\t542\t905\t421\t359\t\n",
      "\n",
      "K = 2 \t103\t252\t241\t1042\t913\t966\t725\t298\t1147\t1118\t\n",
      "\n",
      "K = 3 \t15\t14\t6\t790\t111\t1829\t127\t26\t514\t887\t\n",
      "\n",
      "K = 4 \t161\t2029\t943\t862\t268\t156\t1078\t711\t447\t297\t\n",
      "\n",
      "K = 5 \t321\t42\t529\t225\t1011\t28\t420\t729\t406\t235\t\n",
      "\n",
      "Try Complete.\n",
      "\n",
      "\n",
      "Trying with 7 centroids:\n",
      "\n",
      "\tpop\tmetal\tdisco\tblues\treggae\tclassic\trock\thiphop\tcountry\tjazz\t\n",
      "\n",
      "K = 0 \t283\t28\t437\t183\t913\t21\t355\t623\t325\t196\t\n",
      "\n",
      "K = 1 \t1270\t58\t369\t3\t194\t2\t106\t291\t66\t111\t\n",
      "\n",
      "K = 2 \t142\t1223\t761\t861\t360\t209\t1000\t558\t539\t331\t\n",
      "\n",
      "K = 3 \t14\t13\t5\t748\t97\t1781\t115\t24\t471\t852\t\n",
      "\n",
      "K = 4 \t975\t40\t501\t8\t482\t8\t282\t746\t231\t163\t\n",
      "\n",
      "K = 5 \t231\t1459\t741\t234\t113\t22\t511\t494\t272\t296\t\n",
      "\n",
      "K = 6 \t85\t179\t185\t963\t841\t955\t630\t262\t1093\t1051\t\n",
      "\n",
      "Try Complete.\n",
      "\n",
      "\n",
      "Trying with 8 centroids:\n",
      "\n",
      "\tpop\tmetal\tdisco\tblues\treggae\tclassic\trock\thiphop\tcountry\tjazz\t\n",
      "\n",
      "K = 0 \t1096\t29\t289\t2\t166\t2\t69\t220\t44\t87\t\n",
      "\n",
      "K = 1 \t379\t840\t620\t82\t74\t12\t367\t305\t247\t281\t\n",
      "\n",
      "K = 2 \t12\t12\t5\t691\t81\t1709\t94\t21\t422\t799\t\n",
      "\n",
      "K = 3 \t135\t1436\t755\t546\t189\t80\t735\t574\t286\t184\t\n",
      "\n",
      "K = 4 \t64\t124\t126\t811\t726\t920\t514\t214\t944\t844\t\n",
      "\n",
      "K = 5 \t318\t26\t425\t107\t842\t13\t294\t666\t259\t162\t\n",
      "\n",
      "K = 6 \t860\t25\t322\t4\t380\t6\t206\t624\t162\t88\t\n",
      "\n",
      "K = 7 \t136\t508\t457\t757\t542\t256\t720\t374\t633\t555\t\n",
      "\n",
      "Try Complete.\n",
      "\n",
      "\n",
      "Trying with 9 centroids:\n",
      "\n",
      "\tpop\tmetal\tdisco\tblues\treggae\tclassic\trock\thiphop\tcountry\tjazz\t\n",
      "\n",
      "K = 0 \t164\t1666\t823\t549\t194\t70\t768\t629\t283\t221\t\n",
      "\n",
      "K = 1 \t107\t574\t421\t778\t426\t325\t697\t321\t622\t582\t\n",
      "\n",
      "K = 2 \t572\t569\t601\t48\t53\t11\t315\t266\t245\t267\t\n",
      "\n",
      "K = 3 \t1118\t18\t273\t1\t178\t1\t72\t235\t43\t84\t\n",
      "\n",
      "K = 4 \t13\t69\t35\t604\t154\t1309\t290\t37\t589\t787\t\n",
      "\n",
      "K = 5 \t643\t25\t263\t6\t425\t5\t196\t615\t149\t67\t\n",
      "\n",
      "K = 6 \t8\t5\t1\t495\t54\t1192\t38\t14\t291\t535\t\n",
      "\n",
      "K = 7 \t294\t29\t455\t117\t781\t13\t292\t633\t275\t178\t\n",
      "\n",
      "K = 8 \t81\t45\t127\t402\t735\t72\t331\t248\t500\t279\t\n",
      "\n",
      "Try Complete.\n",
      "\n",
      "\n",
      "Trying with 10 centroids:\n",
      "\n",
      "\tpop\tmetal\tdisco\tblues\treggae\tclassic\trock\thiphop\tcountry\tjazz\t\n",
      "\n",
      "K = 0 \t929\t137\t492\t8\t57\t7\t214\t259\t195\t200\t\n",
      "\n",
      "K = 1 \t103\t245\t286\t632\t443\t317\t508\t235\t602\t665\t\n",
      "\n",
      "K = 2 \t97\t1103\t623\t642\t233\t117\t783\t460\t340\t166\t\n",
      "\n",
      "K = 3 \t89\t24\t128\t252\t707\t32\t265\t242\t323\t104\t\n",
      "\n",
      "K = 4 \t778\t6\t168\t1\t138\t1\t34\t149\t24\t69\t\n",
      "\n",
      "K = 5 \t8\t7\t2\t527\t54\t1291\t47\t15\t300\t577\t\n",
      "\n",
      "K = 6 \t400\t38\t492\t73\t724\t9\t278\t739\t278\t185\t\n",
      "\n",
      "K = 7 \t135\t1346\t593\t208\t77\t20\t425\t368\t172\t203\t\n",
      "\n",
      "K = 8 \t444\t20\t177\t4\t335\t3\t116\t467\t84\t34\t\n",
      "\n",
      "K = 9 \t17\t74\t38\t653\t232\t1201\t329\t64\t679\t797\t\n",
      "\n",
      "Try Complete.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for number_of_centroids in range(2, len(data[\"mapping\"])+1):\n",
    "    print(\"\\nTrying with \" + str(number_of_centroids) + \" centroids:\\n\")\n",
    "    k_means_and_display_by_number_of_cluster_centers(number_of_centroids, normalized_dataset_by_segments, 5)\n",
    "    print(\"Try Complete.\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb54b2f7",
   "metadata": {},
   "source": [
    "## Then, perform K-means clustering algorithm based on each track, where the integrated information (mean, min, max, standard derivation) of 30 samples per track is the base unit for the track-based processing. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffab4bd1",
   "metadata": {},
   "source": [
    "## Track-based processing, unlike sample-based processing (demonstrated above), is intuitively more relevant to music genre classification, where each track is treated as an individual unit rather than just 1 second of each track (that the target of classification is the tracks, not the one-seconds from each track)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "748f184a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 271)\n"
     ]
    }
   ],
   "source": [
    "data_features_by_tracks = [];\n",
    "\n",
    "count = 1;\n",
    "\n",
    "for j in range(len(data[\"tracks\"])):\n",
    "\n",
    "    samples = np.array([data[\"tracks\"][j][i] for i in data[\"tracks\"][j]], dtype=object)\n",
    "    new_new_samples = np.asarray([samples[i] for i in range(len(samples))], dtype=object)\n",
    "    first_row = np.asarray([new_new_samples[0][i] for i in range(len(new_new_samples[0]))], dtype=object)\n",
    "    second_row = np.asarray([new_new_samples[1][i] for i in range(len(new_new_samples[1]))], dtype=object)\n",
    "    third_row = np.asarray([new_new_samples[2][i] for i in range(len(new_new_samples[2]))], dtype=object)\n",
    "    fourth_row = np.asarray([new_new_samples[3][i] for i in range(len(new_new_samples[3]))], dtype=object)\n",
    "    fifth_row = np.asarray([new_new_samples[4][i] for i in range(len(new_new_samples[4]))], dtype=object)\n",
    "    sixth_row = np.asarray([new_new_samples[5][i] for i in range(len(new_new_samples[5]))], dtype=object)\n",
    "    rest = new_new_samples[6:-1].T\n",
    "    labels = new_new_samples[-1].T\n",
    "\n",
    "    dataset = np.concatenate((first_row, second_row, third_row, fourth_row, fifth_row, sixth_row, rest), 1);\n",
    "    dataset = dataset.T\n",
    "    \n",
    "    dataset_by_tracks = np.array([]);\n",
    "    \n",
    "    for k in range(dataset.shape[0]):\n",
    "        \n",
    "\n",
    "        dataset_by_tracks = np.append(dataset_by_tracks, np.min(dataset[k]))\n",
    "        dataset_by_tracks = np.append(dataset_by_tracks, np.max(dataset[k]))\n",
    "        dataset_by_tracks = np.append(dataset_by_tracks, np.mean(dataset[k]))\n",
    "\n",
    "    dataset_by_tracks = np.append(dataset_by_tracks, labels[0])\n",
    "    \n",
    "    if count==1:\n",
    "        data_features_by_tracks = dataset_by_tracks\n",
    "        count-=1\n",
    "    elif count==0:\n",
    "        data_features_by_tracks = np.concatenate(([data_features_by_tracks,]*1, [dataset_by_tracks,]*1), 0)\n",
    "        count-=1\n",
    "    else:\n",
    "        data_features_by_tracks = np.concatenate((data_features_by_tracks, [dataset_by_tracks,]*1), 0)\n",
    "\n",
    "print(data_features_by_tracks.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90660019",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_dataset_by_tracks = data_features_by_tracks\n",
    "normalized_dataset_by_tracks[:,:-1] = normalize(normalized_dataset_by_tracks[:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4349e6f4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trying with 2 centroids:\n",
      "\n",
      "\tpop\tmetal\tdisco\tblues\treggae\tclassic\trock\thiphop\tcountry\tjazz\t\n",
      "\n",
      "K = 0 \t95\t75\t82\t21\t46\t2\t53\t79\t31\t25\t\n",
      "\n",
      "K = 1 \t5\t25\t18\t79\t54\t98\t47\t21\t69\t75\t\n",
      "\n",
      "Try Complete.\n",
      "\n",
      "\n",
      "Trying with 3 centroids:\n",
      "\n",
      "\tpop\tmetal\tdisco\tblues\treggae\tclassic\trock\thiphop\tcountry\tjazz\t\n",
      "\n",
      "K = 0 \t78\t6\t30\t0\t15\t0\t11\t33\t12\t11\t\n",
      "\n",
      "K = 1 \t0\t5\t3\t57\t27\t96\t21\t9\t51\t62\t\n",
      "\n",
      "K = 2 \t22\t89\t67\t43\t58\t4\t68\t58\t37\t27\t\n",
      "\n",
      "Try Complete.\n",
      "\n",
      "\n",
      "Trying with 4 centroids:\n",
      "\n",
      "\tpop\tmetal\tdisco\tblues\treggae\tclassic\trock\thiphop\tcountry\tjazz\t\n",
      "\n",
      "K = 0 \t77\t5\t29\t0\t14\t0\t10\t30\t8\t11\t\n",
      "\n",
      "K = 1 \t0\t2\t0\t35\t5\t83\t7\t0\t21\t40\t\n",
      "\n",
      "K = 2 \t18\t79\t54\t25\t30\t2\t52\t50\t23\t14\t\n",
      "\n",
      "K = 3 \t5\t14\t17\t40\t51\t15\t31\t20\t48\t35\t\n",
      "\n",
      "Try Complete.\n",
      "\n",
      "\n",
      "Trying with 5 centroids:\n",
      "\n",
      "\tpop\tmetal\tdisco\tblues\treggae\tclassic\trock\thiphop\tcountry\tjazz\t\n",
      "\n",
      "K = 0 \t71\t5\t23\t0\t12\t0\t8\t20\t4\t8\t\n",
      "\n",
      "K = 1 \t2\t83\t31\t29\t5\t2\t40\t25\t12\t9\t\n",
      "\n",
      "K = 2 \t21\t1\t29\t0\t30\t1\t17\t34\t15\t9\t\n",
      "\n",
      "K = 3 \t0\t2\t0\t35\t5\t83\t7\t0\t20\t40\t\n",
      "\n",
      "K = 4 \t6\t9\t17\t36\t48\t14\t28\t21\t49\t34\t\n",
      "\n",
      "Try Complete.\n",
      "\n",
      "\n",
      "Trying with 6 centroids:\n",
      "\n",
      "\tpop\tmetal\tdisco\tblues\treggae\tclassic\trock\thiphop\tcountry\tjazz\t\n",
      "\n",
      "K = 0 \t3\t57\t29\t8\t3\t1\t18\t18\t12\t11\t\n",
      "\n",
      "K = 1 \t71\t2\t21\t0\t12\t0\t8\t22\t3\t6\t\n",
      "\n",
      "K = 2 \t3\t4\t5\t34\t35\t14\t20\t12\t45\t23\t\n",
      "\n",
      "K = 3 \t0\t1\t0\t24\t3\t81\t5\t0\t14\t37\t\n",
      "\n",
      "K = 4 \t21\t1\t18\t0\t32\t1\t11\t30\t11\t8\t\n",
      "\n",
      "K = 5 \t2\t35\t27\t34\t15\t3\t38\t18\t15\t15\t\n",
      "\n",
      "Try Complete.\n",
      "\n",
      "\n",
      "Trying with 7 centroids:\n",
      "\n",
      "\tpop\tmetal\tdisco\tblues\treggae\tclassic\trock\thiphop\tcountry\tjazz\t\n",
      "\n",
      "K = 0 \t20\t1\t18\t0\t28\t1\t11\t29\t9\t6\t\n",
      "\n",
      "K = 1 \t2\t57\t29\t8\t3\t1\t18\t18\t13\t11\t\n",
      "\n",
      "K = 2 \t0\t3\t0\t26\t8\t34\t10\t3\t30\t32\t\n",
      "\n",
      "K = 3 \t5\t3\t7\t14\t39\t4\t15\t14\t24\t10\t\n",
      "\n",
      "K = 4 \t0\t0\t0\t18\t1\t57\t2\t0\t7\t21\t\n",
      "\n",
      "K = 5 \t2\t34\t25\t34\t9\t3\t36\t16\t14\t14\t\n",
      "\n",
      "K = 6 \t71\t2\t21\t0\t12\t0\t8\t20\t3\t6\t\n",
      "\n",
      "Try Complete.\n",
      "\n",
      "\n",
      "Trying with 8 centroids:\n",
      "\n",
      "\tpop\tmetal\tdisco\tblues\treggae\tclassic\trock\thiphop\tcountry\tjazz\t\n",
      "\n",
      "K = 0 \t37\t1\t15\t0\t9\t0\t7\t21\t4\t4\t\n",
      "\n",
      "K = 1 \t4\t7\t12\t18\t36\t5\t19\t15\t26\t25\t\n",
      "\n",
      "K = 2 \t39\t0\t10\t0\t4\t0\t2\t6\t1\t3\t\n",
      "\n",
      "K = 3 \t0\t2\t1\t33\t10\t15\t11\t4\t30\t16\t\n",
      "\n",
      "K = 4 \t0\t1\t0\t17\t2\t76\t4\t0\t10\t30\t\n",
      "\n",
      "K = 5 \t2\t35\t27\t28\t7\t3\t32\t16\t8\t5\t\n",
      "\n",
      "K = 6 \t16\t1\t15\t0\t30\t1\t11\t26\t9\t7\t\n",
      "\n",
      "K = 7 \t2\t53\t20\t4\t2\t0\t14\t12\t12\t10\t\n",
      "\n",
      "Try Complete.\n",
      "\n",
      "\n",
      "Trying with 9 centroids:\n",
      "\n",
      "\tpop\tmetal\tdisco\tblues\treggae\tclassic\trock\thiphop\tcountry\tjazz\t\n",
      "\n",
      "K = 0 \t36\t1\t15\t0\t8\t0\t6\t21\t2\t4\t\n",
      "\n",
      "K = 1 \t2\t55\t22\t7\t1\t1\t14\t13\t10\t11\t\n",
      "\n",
      "K = 2 \t2\t35\t27\t33\t6\t3\t34\t17\t10\t6\t\n",
      "\n",
      "K = 3 \t9\t0\t2\t1\t10\t3\t8\t7\t6\t4\t\n",
      "\n",
      "K = 4 \t0\t3\t0\t28\t7\t35\t10\t2\t26\t24\t\n",
      "\n",
      "K = 5 \t0\t0\t0\t14\t1\t55\t2\t0\t7\t21\t\n",
      "\n",
      "K = 6 \t39\t0\t10\t0\t4\t0\t2\t6\t1\t3\t\n",
      "\n",
      "K = 7 \t2\t5\t8\t17\t36\t2\t15\t14\t27\t23\t\n",
      "\n",
      "K = 8 \t10\t1\t16\t0\t27\t1\t9\t20\t11\t4\t\n",
      "\n",
      "Try Complete.\n",
      "\n",
      "\n",
      "Trying with 10 centroids:\n",
      "\n",
      "\tpop\tmetal\tdisco\tblues\treggae\tclassic\trock\thiphop\tcountry\tjazz\t\n",
      "\n",
      "K = 0 \t35\t0\t7\t0\t3\t0\t1\t7\t1\t3\t\n",
      "\n",
      "K = 1 \t0\t53\t16\t4\t0\t0\t11\t11\t7\t9\t\n",
      "\n",
      "K = 2 \t2\t35\t26\t30\t7\t3\t33\t15\t9\t6\t\n",
      "\n",
      "K = 3 \t0\t0\t1\t30\t11\t10\t9\t2\t25\t14\t\n",
      "\n",
      "K = 4 \t38\t2\t19\t0\t9\t0\t7\t20\t3\t4\t\n",
      "\n",
      "K = 5 \t0\t1\t0\t17\t2\t74\t2\t0\t10\t29\t\n",
      "\n",
      "K = 6 \t5\t2\t11\t3\t34\t0\t12\t15\t14\t4\t\n",
      "\n",
      "K = 7 \t13\t1\t14\t0\t18\t1\t10\t20\t10\t4\t\n",
      "\n",
      "K = 8 \t0\t6\t4\t15\t8\t9\t11\t5\t19\t22\t\n",
      "\n",
      "K = 9 \t7\t0\t2\t1\t8\t3\t4\t5\t2\t5\t\n",
      "\n",
      "Try Complete.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for number_of_centroids in range(2, len(data[\"mapping\"])+1):\n",
    "    print(\"\\nTrying with \" + str(number_of_centroids) + \" centroids:\\n\")\n",
    "    k_means_and_display_by_number_of_cluster_centers(number_of_centroids, normalized_dataset_by_tracks, 0)\n",
    "    print(\"Try Complete.\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3725ab2",
   "metadata": {},
   "source": [
    "## Procedure complete. Observations are listed in the report."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
